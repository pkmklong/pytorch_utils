# pytorch_utils (WIP)

<b>Installation</b>

    $ python3 -m pip install git+https://github.com/pkmklong/pytorch_utils.git
 
<i>Synthetic Data Generation</i>

```python
from pytorch.utils import MockDataset

train_dataset = MockDataset(
    features=20,
    pos_n=100,
    neg_n=100,
    pos_mean=150,
    pos_std=80,
    neg_mean=200,
    neg_std=100
)
    
train_dataset.data
>> tensor([[120.8692,  96.8306,  77.1077,  ..., 288.5028, 139.9560,  97.9168],
>>         [ 41.1911, -82.3300, 133.0649,  ..., 295.8810, 375.1372, 178.4848],
>>         [133.8616,  10.1892, 116.5640,  ..., 117.4343, 165.8598, 385.8340],
>>         ...,
>>         [226.8078,  56.6908,  68.1813,  ..., 185.2966, 166.0162, 224.8710],
>>         [243.6762,  99.0662, 165.8202,  ..., 169.0571, 160.4391, 141.3412],
>>         [  7.1814, 268.7216, 274.3542,  ..., 308.0595, 421.0810, 193.6014]],
>>        dtype=torch.float64)

train_dataset.data.shape
>> torch.Size([200, 20])

train_dataset.label
>> tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
>>        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
>>        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
>>        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
>>        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
>>        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
>>        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
>>        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
>>        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
>>        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
>>        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
>>        0., 0.], dtype=torch.float64)


df = train_dataset.to_df(row_ids=True, label=True)
print(df.head())
>>         col_0       col_1       col_2       col_3       col_4       col_5  \
>> 0   76.671783  237.427200   51.926945  144.179871  199.743744  161.962677   
>> 1  142.555237  178.465240  110.335129  183.596283  262.374969  146.972198   
>> 2  127.578300   51.837448   47.730965   23.925421  240.951111  193.342422   
>> 3  167.927338   98.886208  175.795868   12.312732  219.278030  134.566544   
>> 4  204.766968  179.252670  352.789703  242.182266    5.143135  198.371246   
>> 
>>         col_6       col_7       col_8       col_9  ...      col_12  \
>> 0  219.489868  215.356186  240.512527   93.361076  ...  348.179047   
>> 1  278.393219  112.708977  136.901840  224.273987  ...  178.171463   
>> 2   96.553879  215.044968  189.457367  290.033356  ...  267.665771   
>> 3  161.055405  144.950653  264.310760   77.834991  ...  185.965439   
>> 4  224.157150  210.861694  163.702972  221.520844  ...  213.584579   
>> 
>>        col_13      col_14      col_15      col_16      col_17      col_18  \
>> 0   88.440956  129.327255   26.653484  221.484146  138.626617  125.581703   
>> 1  -52.986889   53.843487   37.840637   82.859192   62.900490  197.888824   
>> 2  252.580475  -52.617668   32.906353  137.716858  238.609711  160.608093   
>> 3  365.058746  136.007996  175.964859  255.458557   -9.401795  203.279770   
>> 4  201.123962  156.250916  224.926498  272.791382  -16.865255  153.110565   
>> 
>>        col_19  row_ids  label  
>> 0    9.380897        0    1.0  
>> 1   85.337105        1    1.0  
>> 2  207.362503        2    1.0  
>> 3  154.750854        3    1.0  
>> 4  151.126114        4    1.0  

